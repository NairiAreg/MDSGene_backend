# Filename: .env.docker

# --- Service URLs for Docker internal communication ---
# Ollama runs as a service named 'ollama' in docker-compose
OLLAMA_BASE_URL=http://ollama:11434

# AI Processor runs as a service named 'ai-processor'
AI_PROCESSOR_SERVICE_URL=http://ai-processor:8001

# Vector Store runs as a service named 'vector-store'
VECTOR_STORE_SERVICE_URL=http://vector-store:8002

# --- API Keys and Model Configs (same as your .env.txt) ---
GEMINI_API_KEY=AIzaSyC6OYFD8qEpZXcqL5tCrT4ygvniYbQt37I
GEMINI_MODEL=gemini-2.5-pro-preview-03-25

# --- Model and Processing Configs (same as .env.txt) ---
EMBEDDING_MODEL_NAME=mxbai-embed-large
TIMEOUT_EMBEDDING_SECONDS=60
CHUNK_SIZE=500
CHUNK_OVERLAP=100
USE_VECTOR_STORE=true # Set to true if you want services to attempt to use vector store

# --- Application Specific Paths (these will be relative to /app inside the container due to volume mounts) ---
# Corresponds to /app/
EXCEL_FOLDER=excel
PROPERTIES_DIR=properties
TEMP_UPLOAD_DIR=temp_uploads
VECTOR_STORE_PATH=vector_store/faiss_index
MODEL_SAVE_PATH=Model/RF_model.pkl

# --- Ports (for reference, actual mapping is in docker-compose.yml) ---
# PORT_MAIN_APP=8000 (main.py)
# PORT_AI_PROCESSOR=8001 (ai_processor_service.py)
# PORT_VECTOR_STORE=8002 (vector_store_service.py)

MDSGENE_BASE_URL=http://localhost:3001/